{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This notebook demonstrates how to use the NVIDIA IndeX WebSocket API to connect to a running session and load your own dataset.\n",
    "\n",
    "Let's dive in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "\n",
    "You will require the `websocket-client` python package installed into your environment.\n",
    "\n",
    "You also need to make sure that the `nvindex_util.py` file is available in same path as the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import base64\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from IPython.display import IFrame, Image\n",
    "\n",
    "try:\n",
    "    from websocket import create_connection\n",
    "except:\n",
    "    raise Exeption(\"websocket-client package is missing\")\n",
    "\n",
    "try:\n",
    "    import nvindex_util\n",
    "except:\n",
    "    raise Exception(\"nvindex_util.py is missing from your path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to a running NVIDIA IndeX session\n",
    "\n",
    "Assuming you have a running session, you can just plug it in under in the `TODO` string. You can also use the `SERVICE_ENDPOINT` environment variable\n",
    "\n",
    "Examples of endpoint urls for a running session would be:\n",
    "- `http://localhost:8080`\n",
    "- `https://nvindex.app.cloud.example.com`\n",
    "\n",
    "Next, you also have to fill in the credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN SESSION URL\n",
    "service=os.getenv(\"SERVICE_ENDPOINT\", None)\n",
    "# FILL IN YOUR PASSWORD\n",
    "user='nvindex'\n",
    "password='test123'\n",
    "\n",
    "if service == None or password == None:\n",
    "    raise Exception(\"Session URL and/or password are missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get WebSocket endpoint url: http -> ws (just for brevity)\n",
    "service_ws=service.replace(\"http\", \"ws\")\n",
    "print(service)\n",
    "print(service_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting the Notebook to the NVIDIA IndeX session \n",
    "\n",
    "Now we can establish a connection to the server to receive the NVIDIA IndeX viewer and embed the viewer in the notebook. In this demo the render service delivers the NVIDIA IndeX HTML5 viewer with extended user-interface. Generally, this render service can be configured to deliver the interactive video stream or single images only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IFrame(f\"{service}\", width=980, height=650)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with the WebSocket API\n",
    "\n",
    "As you can see, a default (synthetic) volume is already loaded. Let's use the WebSocket API to clear the volume and it's associated scene. To do that, we need to connect to the command WebSocket url for sending commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_command_url = f\"{service_ws}/index_command_client\"\n",
    "print(f\"Command WebSocket url: f{ws_command_url}\")\n",
    "ws = nvindex_util.get_websocket(ws_command_url, credentials=(user, password))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WebSockets are used by the NVIDIA IndeX viewer in 2 ways:\n",
    "- The H.264 encoded video stream is sent over a WebSocket to the browser.\n",
    "- The command WebSocket is used to control the viewer by issuing JSON RPC like commands.\n",
    "\n",
    "The simplest way to clear the volume is to clear the whole scene graph. Let's send a JSON RPC command to do just that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the command to fetch all scene elements\n",
    "ok, ret = nvindex_util.send_jsonrpc_command(ws, {\n",
    "  \"method\": \"nv::index::app::scene_management_center::scene_management_center_command_receiver.get_scene_graph\",\n",
    "  \"params\": {\n",
    "      \"scene_graph_representation_type\": \"tree\"                              \n",
    "  }                          \n",
    "})\n",
    "\n",
    "assert(ok is True)\n",
    "\n",
    "# Now clear each individual element\n",
    "children = ret.get('result', {}).get('tree', {}).get('children', [])\n",
    "for ch in children:                \n",
    "  ok, ret = nvindex_util.send_jsonrpc_command(ws, {\n",
    "      \"method\": \"nv::index::app::scene_management_center::scene_management_center_command_receiver.set_scene_element\",\n",
    "      \"params\": {\n",
    "          \"id\": \"scene_root\",                                                                                            \n",
    "          \"args\": { \n",
    "              \"remove.id\": ch['id']   \n",
    "          }                                              \n",
    "      }                                                         \n",
    "   }) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should see a black canvas with an empty scene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(f\"{service}\", width=980, height=650)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a raw volume dataset\n",
    "\n",
    "Now we are ready to load a dataset. We will be using the sample Supernova dataset (for more information see our [sample dataset page](https://github.com/NVIDIA/nvindex-cloud/blob/master/doc/datasets.md). The dataset has an extent of 633 voxels on each axis.\n",
    "\n",
    "IndeX can load data from local disk, from cloud storage (Google Storage, AWS S3, Azure Blob Storage) or directly over HTTP/HTTPS as long as the server supports byte ranges. We will use the latter option for simplicity: downloading from S3 via HTTP.\n",
    "\n",
    "To add a dataset from scratch, we have to set up a scene that contains at least the following scene elements:\n",
    "a colormap and a volume scene element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"https://nvindex-datasets-us-west2.s3.us-west-2.amazonaws.com/scenes/00-supernova_ncsa_small/data/Export_entropy_633x633x633_uint8_T1074.raw\"\n",
    "bbox = \"0 0 0 633 633 633\"\n",
    "colormap_path = \"https://nvindex-datasets-us-west2.s3.us-west-2.amazonaws.com/scenes/00-supernova_ncsa_small/scene/colormaps/nova03.cmap\"\n",
    "\n",
    "ok, ret = nvindex_util.send_jsonrpc_command(ws, {\n",
    "  \"method\": \"nv::index::app::scene_management_center::scene_management_center_command_receiver.create_scene_element\",\n",
    "  \"params\": {\n",
    "      \"parent_group_id\": \"scene_root\",\n",
    "      \"new_scene_element_id\": f\"my_colormap\",\n",
    "      \"class_name\": \"IColormap\",\n",
    "      \"args\": {\n",
    "          \"map_type\": \"data\",\n",
    "          \"data_source\": \"file\",\n",
    "          \"file_type\": \"cmap\",\n",
    "          \"file_name\": colormap_path,\n",
    "          \"domain_boundary_mode\": \"clamp_to_edge\",\n",
    "      }\n",
    "  }\n",
    "})\n",
    "\n",
    "ok, ret = nvindex_util.send_jsonrpc_command(ws, {\n",
    "  \"method\": \"nv::index::app::scene_management_center::scene_management_center_command_receiver.create_scene_element\",\n",
    "  \"params\": {\n",
    "      \"parent_group_id\": \"scene_root\",\n",
    "      \"new_scene_element_id\": \"my_volume\",\n",
    "      \"class_name\": \"ISparse_volume_scene_element\",\n",
    "      \"args\":  {\n",
    "          \"type\": \"sparse_volume\",\n",
    "          \"bbox\": bbox,\n",
    "          \"importer\": \"nv::index::plugin::base_importer.Sparse_volume_importer_raw\",\n",
    "          \"input_file\": data_path,\n",
    "          \"convert_zyx_to_xyz\": \"false\",\n",
    "          \"voxel_format\": \"uint8\",\n",
    "      }\n",
    "  }\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to wait for the data to be loaded..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvindex_util.wait_for_data_to_load(ws)\n",
    "IFrame(f\"{service}\", width=980, height=650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
